---
title: "Practica Fundamentos"
author: "Juan - Jose - Moncef"
date: "17/12/2021"
output:
  html_document:
    theme: united
    code_folding: "hide"
    toc: yes
    toc_float: yes
---

## Ajuste, interpretación y diagnosis del modelo de regresión lineal múltiple

```{r setup, include=FALSE}
#Librerias

#Librerias
library(MASS)
library(tidyr)
library(date)
library(zoo)
#library(tidyverse)#--> para funciones de fechas#
library(ggplot2)
#library(corrplot)
#library(caret)
library(dplyr)
library(olsrr)
library(fastDummies)
#library(pracma)
#library(geosphere)
#library(readxl)
library(glmnet)
library(emmeans)
library(stargazer)
library(regclass)
library(car)
library(lsr)


train <- as.data.frame(read.csv(file = 'C:/Users/n0375471/OneDrive - Liberty Mutual/Documentos/house_king_county/house_king_county-Moncef/train_final.csv'))

test_final <- as.data.frame(read.csv(file = 'C:/Users/n0375471/OneDrive - Liberty Mutual/Documentos/house_king_county/house_king_county-Moncef/test_final.csv'))


#train = train  %>% filter(price_m2_log < quantile(price_m2_log,0.95))

```


En este apartado, hemos estimado varios modelos a partir de distintas metodologías para poder comparar cual de ellos nos arroja mejores resultados, esto es, menor error cuadratico medio. Para ello, se han estimado los siguientes modelos:

- Modelo con la variables respuesta "log_price_m2" : en este modelo utilizamos la variable respuesta dividida por los metros cuadrados con el objetivo de estabilizar la variable "price", variable con mucha dispersión.

- Modelo con la variables respuesta sugeridas por la regresión LASSO : en este modelo utilizamos de nuevo la variable respuesta dividida por los metros cuadrados, siendo las variables explicativas aquellas seleccionadas por la regresión LASSO.

- Modelo con la variables respuesta sugeridas por su capacidad de reducción del AIC : en este modelo utilizamos de nuevo la variable respuesta dividida por los metros cuadrados, siendo las variables explicativas aquellas que mayor aportación tienen en términos de reducción del AIC.


Para los dos modelos iniciales, la metodología de selección de variables ha sido similar a un proceso "backwards". Se han introducido todas las variables (previa limpiza de aquellas con mayor correlación entre si) y se ha estimado el modelo. Para aquellas variables que el modelo consideraba que no son significativas, estas son eliminadas y se estima un nuevo modelo. Este proceso se repite de forma recursiva hasta que todas las variables incluidas resulten significativas. 



```{r, include=FALSE}

#specify_decimal
specify_decimal <- function(x, k) format(round(x, k), nsmall=k)

#beautifying summary.lm
new_summary  <- function(lmcoef, digits) {
  
  coefs <- as.data.frame(lmcoef)
  coefs[] <- lapply(coefs, function(x) specify_decimal(x, digits))
  coefs
  
}


```



# Modelo con la variables respuesta "log_price_m2"

En este apartado estimamos un modelo con la variables respuesta "log_price_m2". Para este modelo utilizamos la variable respuesta dividida por los metros cuadrados con el objetivo de estabilizar la variable "price", la cual presenta una gran dispersión.



```{r}

train_v1 <- na.omit(train)
train_v1$sqft_basement_log = log(train_v1$sqft_basement)

#Incluimos en c() las variables que NO queremos usar en la regresiÃ³n.
train_v2 = dplyr::select(train,-c(sale_quarter_Q1,sale_quarter_Q4,floors, sale_quarter_Q3,price_m2,id,sale_tenure_log,yr_renovated,sqft_above,sqft_lot,sale_tenure,yr_renovated,sqft_living,Dist_from_seattle,price,date,zipcode,sqft_basement,lat,sqft_lot15,long,date,sale_date,sqft_above_log,sale_year,yr_built,sale_month,yr_since_last_renovated,sqft_living15))


model <- lm(price_m2_log ~ . , data = train_v2)
summary(model)
new_summary(summary(model)$coefficients, 5)

plot(model, which=1, col=c("blue"))
plot(model, 2)

require(nortest)  # Se debe haber instalado nortest
lillie.test(model$residuals)


gvlma(model)
car::vif(model)

```


```{r}

#Test bondad del auste para los residuos del modelo con log_price_m2

require(nortest)  # Se debe haber instalado nortest
(lillie.test(model $residuals))


```

En este segundo modelo, podemos ver que el R2 ajustado es del 71%, 14% puntos mayor al modelo inicial. Por otra parte, el grafico de los residuos no muestra una tendencía como el modelo anterior y parece que los residuos fluctuan alrededor de la media, siendo la varianza relativamente constante.

No obstante, tanto el Q-Q plot como el test de bondad de ajuste realizado sobre los residuos nos hacen rechazar la hipótesis nula de normalidad de los residuos. 


```{r}

test_final <- as.data.frame(read.csv(file = 'C:/Users/n0375471/OneDrive - Liberty Mutual/Documentos/house_king_county/house_king_county-Moncef/test_final.csv'))
test_pred_model <- predict(model,newdata=test_final)

test_y   <- test_final$price_m2_log

SS.total      <- sum((test_y - mean(test_y))^2)
SS.residual   <- sum((test_y - test_pred_model)^2)
SS.regression <- sum((test_pred_model- mean(test_y))^2)
SS.total - (SS.regression+SS.residual)
# [1] 8958890

# NOT the fraction of variability explained by the model
test.rsq <- SS.residual/SS.total  
test.rsq
# [1] 0.0924713

# fraction of variability explained by the model
(r2 = SS.regression/SS.total) 
# [1] 0.08956405

```

Este modelo arroja un R2 del 70% en la base de datos "test".

# Modelo con la variables respuesta sugeridas por la regresión LASSO

Para este modelo utilizamos de nuevo la variable respuesta dividida por los metros cuadrados, siendo las variables explicativas aquellas seleccionadas por la regresión LASSO.


```{r, include=FALSE}

train_v2_nona <- na.omit(train_v2)

x <- model.matrix(log(train_v2_nona$price_m2)~., train_v2_nona )[,-1]
y <- log(train_v2_nona$price_m2)


lambdas <- model.matrix(price_m2_log ~., data = train_v2_nona)


```



```{r}

# Ajuste de la funciÃ³n de error
cv_lasso <- cv.glmnet(x = lambdas, y = y, alpha = 1)
plot(cv_lasso)


out_eleven <- glmnet(lambdas,y,alpha=1,lambda = cv_lasso$lambda.1se)
out_eleven
coef(out_eleven )
cv_lasso

```

Observamos que la regresión LASSO minimiza el error con 29 variables, si bien con 25 variables el error apenas incrementa. A partir de esta 25 variables propuestas por esta metodología, estimamos un nuevo modelo y realizamos un test de bondad del ajuste sobre sus residuos:


```{r}

# Test de normalidad de residuos
preds_lasso <- predict(out_eleven,lambdas)
residuals_lasso <- y - preds_lasso
lillie.test(residuals_lasso)

rsq_lasso <- cor(y, preds_lasso)^2
sprintf("R2 = %f", rsq_lasso)


```


Nuevamente rechzamos la hipótesis de normalidad de los residuos. Por otra parte el R2 de este modelo ha bajado en 1% respecto al modelo anterior, situandose en el 70.6%

Este modelo arroja un R2 del 66% en la base de datos "test".


# Modelo con la variables respuesta sugeridas por su capacidad de reducción del AIC

En este modelo utilizamos de nuevo la variable respuesta dividida por los metros cuadrados, siendo las variables explicativas aquellas que mayor aportación tienen en términos de reducción del AIC.

```{r}

#Analisis de variables candidatas 
step_model <- stepAIC(model, trace = TRUE, direction= "both")
#stargazer(model, step_model, type = "text")


```

Observamos que a partir de la variable "bedrooms", el aporte del resto de variables a la redución del AIC es mínimo. Estableciendo el humbral de forma arbitraria en 5.5, estimamos un nuevo modelo basado en en las variables que superan el umbral propuesto, siendo el número de variables de 18.


```{r}

train_v2 = dplyr::select(train,-c(price_m2,id,sale_tenure_log,yr_renovated,sqft_above,sqft_lot,sale_tenure,yr_renovated,sqft_living,Dist_from_seattle,price,date,zipcode,sqft_basement,lat,sqft_lot15,long,date,sale_date,sqft_above_log,sale_year,yr_built,sale_month,yr_since_last_renovated,sqft_living15))


model_AIC <- lm(price_m2_log ~ +sqft_living_log + grade + Clusters_1 + Clusters_4 + Clusters_5 + Dist_from_seattle_log + Clusters_11 
                + Clusters_8 + view + condition + waterfront_1 + Clusters_10 + Clusters_6 + floors + sale_quarter_Q3 + sale_quarter_Q4  
                  +bedrooms, data = train_v2)


summary(model_AIC)

summary(model_AIC)
new_summary(summary(model_AIC)$coefficients, 5)

plot(model_AIC, which=1, col=c("blue"))
plot(model_AIC, 2)
car::vif(model_AIC)
gvlma(model_AIC)



```

A la vista de los resultados, podemos observar que el R2 se situa en 70.23%, ligeramente inferior a los dos modelos anteriores, si bien el modelo se ha estimado con 7 variables menos, lo que nos permite concluir que estas 7 variable no aportan una gran capacidad explicativa al modelo.


```{r}

require(nortest)  # Se debe haber instalado nortest
lillie.test(model_AIC$residuals)


```

```{r, include= False}

test_pred_model_AIC <- predict(model_AIC,newdata=test_final)

test_y   <- test_final$price_m2_log

SS.total      <- sum((test_y- mean(test.y))^2)
SS.residual   <- sum((test_y - test_pred_model_AIC)^2)
SS.regression <- sum((test_pred_model_AIC- mean(test_y))^2)
SS.total - (SS.regression+SS.residual)
# [1] 8958890

# NOT the fraction of variability explained by the model
test.rsq <- SS.residual/SS.total  
test.rsq
# [1] 0.0924713

# fraction of variability explained by the model
(r2 = SS.regression/SS.total) 
# [1] 0.08956405

```

Este modelo arroja un R2 del 68.6% en la base de datos "test".


## Conclusiones

Las principales conclusiones han sido las siguientes:

* En análisis inicial no ha permitido conocer los datos y sus principales medidas. Asímismo, hemos podido crear nuevas variables que no han sido de gran utilidad a la hora de estimar algunos modelos.

*  Mediante el análisis multivariantes, donde hemos podido analizar tanto las variables entre si como las variables frente a la variable respuesta, se ha podido detrminar que variables nos ayudan a explicar mejor la variable respuesta, asi como aquellas vatriables a excluir para no incurrir en multicolinealidad. Por otra parte, algunas variables que mantenian una relación no lineal con las variable respuesta han sido transformadas para forzar una relación lineal. 

* En cuanto a los modelos, ninguno de ellos logra que los residuos sean ruido blanco, asi como evitar la heterocedasticidad. No obstante, el R2 observado para todos los modelos en la base de datos "test" es bueno, lo que indica que los modelos son estables a pesar de no cumplir las principales hipótesis de la regresión lineal.





