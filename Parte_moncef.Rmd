---
title: "Practica Fundamentos"
author: "Juan - Jose - Moncef"
date: "17/12/2021"
output:
  html_document:
    theme: united
    code_folding: "hide"
    toc: yes
    toc_float: yes
---

## Ajuste, interpretación y diagnosis del modelo de regresión lineal múltiple

```{r setup, include=FALSE}
#Librerias

#Librerias
library(MASS)
library(tidyr)
library(date)
library(zoo)
#library(tidyverse)#--> para funciones de fechas#
library(ggplot2)
#library(corrplot)
#library(caret)
library(dplyr)
library(olsrr)
library(fastDummies)
#library(pracma)
#library(geosphere)
#library(readxl)
library(glmnet)
library(emmeans)
library(stargazer)


train <- as.data.frame(read.csv(file = 'C:/Users/n0375471/OneDrive - Liberty Mutual/Documentos/house_king_county/house_king_county-Moncef/train.csv'))

```


En este apartado, hemos estimado varios modelos a partir de distintas metodologías para poder comparar cual de ellos nos arroja mejores resultados, esto es, menor error cuadratico medio. Para ello, se han estimado los siguientes modelos:

- Modelo inicial con la variable respuesta "price": se trata del modelo con la variable original "price" y sin las variables "Cluster" y "Dist_from_Seattle". Es un modelo inicial de partida para ver como mejora o empeora el R2 al añadir nuevas variables o una transformación de la variable respuesta.

- Modelo con la variables respuesta "log_price_m2" : en este modelo utilizamos la variable respuesta dividida por los metros cuadrados con el objetivo de estabilizar la variable "price", variable con mucha dispersión.

- Modelo con la variables respuesta sugeridas por la regresión LASSO : en este modelo utilizamos de nuevo la variable respuesta dividida por los metros cuadrados, siendo las variables explicativas aquellas seleccionadas por la regresión LASSO.

- Modelo con la variables respuesta sugeridas por su capacidad de reducción del AIC : en este modelo utilizamos de nuevo la variable respuesta dividida por los metros cuadrados, siendo las variables explicativas aquellas que mayor aportación tienen en términos de reducción del AIC.


Para los dos modelos iniciales, la metodología de selección de variables ha sido similar a un proceso "backwards". Se han introducido todas las variables (previa limpiza de aquellas con mayor correlación entre si) y se ha estimado el modelo. Para aquellas variables que el modelo consideraba que no son significativas, estas son eliminadas y se estima un nuevo modelo. Este proceso se repite de forma recursiva hasta que todas las variables incluidas resulten significativas. 



```{r, include=FALSE}

#Convertimos las variables ctageoricas en dummies para su uso en el modelo.

train_v1<- dummy_cols(train, select_columns = c('waterfront','view','Clusters','sale_quarter'),remove_most_frequent_dummy = TRUE,
                   remove_selected_columns = TRUE)

train_v1$sqft_lot_log = log(train_v1$sqft_lot)
train_v1$sqft_above_log = log(train_v1$sqft_above)
train_v1$sqft_living_log = log(train_v1$sqft_living)
train_v1$Dist_from_seattle_log = log(train_v1$Dist_from_seattle)
#train_v1$yr_renovated_log = log(train_v1$yr_renovated)
#train_v1$sale_tenure_log = log(train_v1$sale_tenure)

#specify_decimal
specify_decimal <- function(x, k) format(round(x, k), nsmall=k)

#beautifying summary.lm
new_summary  <- function(lmcoef, digits) {
  
  coefs <- as.data.frame(lmcoef)
  coefs[] <- lapply(coefs, function(x) specify_decimal(x, digits))
  coefs
  
}


```



#Modelo inicial con la variable respuesta "price".


Estimamos el modelo con la variable original "price" y sin las variables "Cluster" y "Dist_from_Seattle". Es un modelo inicial de partida para ver como mejora o empeora el R2 al añadir nuevas variables o una transformación de la variable respuesta:

```{r}

#Incluimos en c() las variables que NO queremos usar en la regresiÃ³n.
train_v2 = dplyr::select(train_v1,-c(id,sale_tenure,yr_renovated,sqft_above,sqft_lot,sale_tenure,
                                     yr_renovated,sqft_living,Dist_from_seattle,date,zipcode,sqft_basement,lat,sqft_lot15,long,date,sale_date,
                                     sale_year,yr_built,sale_month,yr_since_last_renovated,sqft_living15,price_m2,Dist_from_seattle_log, 
                                     Clusters_1,      
Clusters_3, 
Clusters_4,      
Clusters_5,   
Clusters_6,      
Clusters_7,   
Clusters_8,      
Clusters_9,   
Clusters_10,      
Clusters_11,   
Clusters_12,      
Clusters_13,      
Clusters_8))

model_inicial <- lm(price ~ ., data = train_v2)
summary(model)
new_summary(summary(model_inicial )$coefficients, 5)


plot(model_inicial , which=1, col=c("blue"))
plot(model_inicial , 2)


```


```{r}

#Test bondad del auste para los residuos

require(nortest)  # Se debe haber instalado nortest
(lillie.test(model_inicial $residuals))


```

En este primer modelo, podemos ver que el R2 ajustado es del 57%. Por otra parte, el grafico de los residuos muestra cierta tendencía, lo que nos puede indicar que hay algún tipo de relación no lineal entre los regresores y la variable independiente. Por último, tanto  Q-Q plot como el test de bondad de ajuste realizado sobre los residuos nos hacen rechazar la hipótesis nula de normalidad de los residuos. 




#Modelo con la variables respuesta "log_price_m2"

En este apartado estimamos un modelo con la variables respuesta "log_price_m2". Para este modelo utilizamos la variable respuesta dividida por los metros cuadrados con el objetivo de estabilizar la variable "price", la cual presenta una gran dispersión.

```{r}

#Incluimos en c() las variables que NO queremos usar en la regresiÃ³n.
train_v2 = dplyr::select(train_v1,-c(id,sale_tenure,yr_renovated,sqft_above,sqft_lot,sale_tenure,yr_renovated,sqft_living,Dist_from_seattle,price,date,zipcode,sqft_basement,lat,sqft_lot15,long,date,sale_date,
                              sale_year,yr_built,sale_month,yr_since_last_renovated,sqft_living15))


model <- lm(log(price_m2) ~ ., data = train_v2)
summary(model)
new_summary(summary(model)$coefficients, 5)

plot(model, which=1, col=c("blue"))
plot(model, 2)

require(nortest)  # Se debe haber instalado nortest
lillie.test(model$residuals)



```

```{r}

#Test bondad del auste para los residuos del modelo con log_price_m2

require(nortest)  # Se debe haber instalado nortest
(lillie.test(model $residuals))


```

En este segundo modelo, podemos ver que el R2 ajustado es del 71%, 14% puntos mayor al modelo inicial. Por otra parte, el grafico de los residuos no muestra una tendencía como el modelo anterior y parece que los residuos fluctuan alrededor de la media, siendo la varianza relativamente constante.

No obstante, tanto el Q-Q plot como el test de bondad de ajuste realizado sobre los residuos nos hacen rechazar la hipótesis nula de normalidad de los residuos. 


#Modelo con la variables respuesta sugeridas por la regresión LASSO

Para este modelo utilizamos de nuevo la variable respuesta dividida por los metros cuadrados, siendo las variables explicativas aquellas seleccionadas por la regresión LASSO.


```{r, include=FALSE}

train_v2_nona <- na.omit(train_v2)

x <- model.matrix(log(train_v2_nona$price_m2)~., train_v2_nona )[,-1]
y <- log(train_v2_nona$price_m2)


lambdas <- model.matrix(log(price_m2) ~., data = train_v2_nona)


```



```{r}

# Ajuste de la funciÃ³n de error
cv_lasso <- cv.glmnet(x = lambdas, y = y, alpha = 1)
plot(cv_lasso)


out_eleven <- glmnet(lambdas,y,alpha=1,lambda = cv_lasso$lambda.1se)
out_eleven
coef(out_eleven )
cv_lasso


```

Observamos que la regresión LASSO minimiza el error con 29 variables, si bien con 25 variables el error apenas incrementa. A partir de esta 25 variables propuestas por esta metodología, estimamos un nuevo modelo y realizamos un test de bondad del ajuste sobre sus residuos:


```{r}

# Test de normalidad de residuos
preds_lasso <- predict(out_eleven,lambdas)
residuals_lasso <- y - preds_lasso
lillie.test(residuals_lasso)

rsq_lasso <- cor(y, preds_lasso)^2
sprintf("R2 = %f", rsq_lasso)


```


Nuevamente rechzamos la hipótesis de normalidad de los residuos. Por otra parte el R2 de este modelo ha bajado en 1% respecto al modelo anterior, situandose en el 70.6%


#Modelo con la variables respuesta sugeridas por su capacidad de reducción del AIC

En este modelo utilizamos de nuevo la variable respuesta dividida por los metros cuadrados, siendo las variables explicativas aquellas que mayor aportación tienen en términos de reducción del AIC.

```{r}

#Analisis de variables candidatas 
step_model <- stepAIC(model, trace = TRUE, direction= "both")
#stargazer(model, step_model, type = "text")


```

Observamos que a partir de la variable "bathrooms", el aporte del resto de variables a la redución del AIC es mínimo. Estableciendo el humbral de forma arbitraria en 5.5, estimamos un nuevo modelo basado en en las variables que superan el umbral propuesto, siendo el número de variables de 18.


```{r}

model_AIC <- lm(log(price_m2) ~ bedrooms + bathrooms + floors + condition
                  + grade + waterfront_1 + view_1 + view_2 + view_3 + view_4 + Clusters_1 + Clusters_3 
                  + Clusters_4+ Clusters_6  + Clusters_8 
                  + Clusters_9 + Clusters_11 + Clusters_13
                  + sale_quarter_Q3 +sale_quarter_Q4+ sqft_lot_log +  sqft_above_log + sqft_living_log + Dist_from_seattle_log, data = train_v2)

model_AIC <- lm(log(price_m2) ~ bathrooms + condition
                  + grade + waterfront_1 + view_1 + view_2 + view_3 + view_4 + Clusters_1 + Clusters_3 
                  + Clusters_4+ Clusters_6  + bathrooms
                  + Clusters_9 + Clusters_11 
                  + sqft_lot_log +  sqft_above_log + sqft_living_log + Dist_from_seattle_log, data = train_v2)
summary(model_AIC)

summary(model_AIC)
new_summary(summary(model_AIC)$coefficients, 5)

plot(model_AIC, which=1, col=c("blue"))
plot(model_AIC, 2)


```

A la vista de los resultados, podemos observar que el R2 se situa en 70.23%, ligeramente inferior a los dos modelos anteriores, si bien el modelo se ha estimado con 7 variables menos, lo que nos permite concluir que estas 7 variable no aportan una gran capacidad explicativa al modelo.


```{r}

require(nortest)  # Se debe haber instalado nortest
lillie.test(model_AIC$residuals)


```



## Conclusion

